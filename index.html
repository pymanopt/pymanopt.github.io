<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML+RDFa 1.1//EN" "http://www.w3.org/MarkUp/DTD/xhtml-rdfa-2.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" dir="ltr" id="index">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>Pymanopt</title>

    <!-- mathjax -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    <!-- code-prettify -->
    <script type="text/javascript" src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?lang=py"></script>

    <link href="layout.css" rel="stylesheet" type="text/css" />
</head>

<body>

<h1>Pymanopt</h1>

<p>Pymanopt is a python toolbox for manifold optimization that computes
gradients and hessians automatically. It builds upon the MATLAB package
<a href="http://manopt.org/">Manopt</a> but is otherwise independent of
it. Pymanopt aims to lower the barriers for users wishing to use state
of the art manifold optimization techniques even further, by relying on
automatic differentiation for computing gradients and hessians, saving
users time and saving them from potential calculation and
implementiation errors.</p>

<p>Pymanopt is modular and hence easy to use. Usually only the following
steps are required:</p>
<ol>
    <li>defininition of the cost function $f:\mathcal{M}\to \mathbb{R}$
    to minimise</li>
    <li>instantiation of the respective manifold $\mathcal{M}$ to
    optimise over</li>
    <li>instantiation of a Pymanopt solver</li>
</ol>

<p>Experimenting with Riemannian optimisation is simple with Pymanopt
and gradients and hessians are computed automatically if needed by the
chosen solver. The following example demonstrates the ease of use while
the steps will be discussed in more detail in the subsequent three
sections.</p>

<pre class="prettyprint"><code class="language-py">
import autograd.numpy as np

from pymanopt import Problem
from pymanopt.solvers import SteepestDescent
from pymanopt.manifolds import Stiefel

# (1) definition of the cost function (here using theano)
def cost(X): return np.sum(X)

# (2) instantiation of the respective manifold
manifold = Stiefel(5, 2)

# (3) instantiation of a Pymanopt solver
solver = SteepestDescent()

# let Pymanopt do the rest
problem = Problem(manifold=manifold, cost=cost)
Xopt = solver.solve(problem)
print(Xopt)
</code></pre>

<p><strong>We explicitly encourage users to report problems, request features,
ask for help, or leave general comments either on
<a href="https://github.com/pymanopt/pymanopt">github</a>,
<a href="https://gitter.im/pymanopt/pymanopt">gitter</a>, or via email to
one of the maintainers.</strong></p>


<h2>(0) Installing Pymanopt</h2>

<p>Pymanopt can be installed with the following command:</p>
<pre class="prettyprint"><code class="language-bash">
pip install --user git+https://github.com/pymanopt/pymanopt.git
</code></pre>

<p>Pymanopt is compatible with Python 2.7 and Python 3.3+, and depends on
numpy, scipy (and theano or autograd). Instructions for installing numpy,
scipy, and theano on different operating systems can be found
<a href="http://deeplearning.net/software/theano/install.html">here</a>,
for installing autograd
<a href="https://github.com/HIPS/autograd#how-to-install">here</a>.</p>


<h2>(1) Cost Functions</h2>

<p>The python cost function passed to Pymanopt should take a single input,
a point on the manifold, and return a scalar. There are the following three
alternatives as to how to optimise, i.e. minimise, this cost function
using Pymanopt:</p>
<ol class="alpha">
    <li>Rely on Pymanopt's autodiff backend to automatically compute the gradient and hessian</li>
    <li>Implement the gradient and hessian manually and pass it over to Pymanopt</li>
    <li>Use one of the derivative-free solver algorithms</li>
</ol>

<p>The first approach is recommended â€“ indeed, it is what makes experimenting
with Riemannian optimisation so easy!</p>

<h3>(a) Rely on Pymanopt's autodiff backend</h3>

<p>Currently Pymanopt supports theano and autograd as autodiff backends
and we plan on implementing a tensorflow backend.
How the cost function has to be implemented depends on which backend,
autograd or theano, is to be used.</p>

<h4>Setting up the cost function for using the autograd autodiff backend</h4>

<pre class="prettyprint"><code class="language-python">
import autograd.numpy as np
def cost(X): return np.sum(X)
problem = Problem(manifold=manifold, cost=cost)
</code></pre>


<h4>Setting up the cost function for using the theano autodiff backend</h4>

<pre class="prettyprint"><code class="language-python">
import theano.tensor as T
X = T.matrix()
cost = T.sum(X)
problem = Problem(manifold=manifold, cost=cost, arg=[X])
</code></pre>


<h3>(b) Implement gradient and hessian manually</h3>

<p>The free gradient and, if needed by the chosen solver, the hessian need
to be implemented as python function that take as input a point on the
manifold and returns the gradient or hessian at that point respectively.
These then need to be passed over to Pymanopt's Problem class:</p>
<pre class="prettyprint"><code class="language-python">
problem = Problem(manifold=manifold, cost=cost, egrad=egrad, ehess=ehess)
</code></pre>
<p>Again, we recommend the first approach that save you time deriving and
implementing the gradient and hessian. If you need the gradient and hessian
for analytical reasons, you can check your manually derived derivatives
using <a href="doc/index.html#module-pymanopt.tools.testing">Pymanopt's
testing module</a>.</p>


<h3>(c) Use a derivative-free solver</h3>

<p>Currently NelderMead and ParticleSwarm are available as derivative-free
solvers. If using one of those, only the manifold and cost function need
to be passed over to Pymanopt's Problem class:</p>
<pre class="prettyprint"><code class="language-python">
problem = Problem(manifold=manifold, cost=cost)
</code></pre>
<p>Again, Pymanopt's autodiff backend makes it really easy to also use
solvers that rely on the gradient and hessian.</p>


<h2>(2) Manifolds</h2>

<p>The Pymanopt Manifold class provides manifold specific routines like
computing the intrinsic mean of two points on the manifold or computing
the geodesic distance. The user will only need to instantiate the
correct manifold and need not worry about the internal workings. We plan
on implementing further manifolds as needed by the users. Developers
wanting to implement a new manifold for Pymanopt are referred to the
<a href="doc/index.html#module-pymanopt.manifolds.manifold">Manifold
abstract base class</a>.</p>

<h3>List of Manifolds</h3>

<table id="manifolds">

<tr>
    <th>manifold</th>
    <th>description</th>
    <th>required codelines</th>
</tr>

<tr>
    <td>Euclidean manifold<br />
    $\mathbb{R}^{m\times n}$</td>
    <td>Euclidean space of $m\times n$ matrices equipped with the
    Frobenius distance and trace inner product. Helpful for
    unconstrained problems or, when used as part of a product manifold,
    for unconstrained hyperparameters.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Euclidean
manifold = Euclidean(m,n)
</code></pre>
    </td>
</tr>

<tr>
    <td>Grassmann manifold<br />
    $G_{m,n} \triangleq \{\operatorname{Span}\{M\}:M\in\mathbb{R}^{m\times n}\}$</td>
    <td>This is the manifold of $n$-dimensional subspaces of $\mathbb{R}^m$. For optional argument $k>1$ this instantiates the product $\mathcal{Gr}^{m\times n}\times\cdots\times\mathcal{Gr}^{m\times n}$ of $k$ Grassmann manifolds.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Grassmann
manifold = Grassmann(m,n)
</code></pre>
    </td>
</tr>

<tr>
    <td>Oblique manifold<br />
    $O_{m,n} \triangleq \{M\in\mathbb{R}^{m\times n}: ||M_{:,j}||_2=1 \ \forall j\in\mathbb{N}_1^n\}$</td>
    <td>Manifold of matrices with unit-norm columns.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Oblique
manifold = Oblique(m,n)
</code></pre>
    </td>
</tr>

<tr>
    <td>Elliptope manifold<br />
    $E_k^n \triangleq \{M\in\mathbb{R}^{n\times n}: M \succeq \mathbf{0}, \operatorname{rank}(M)=k, ||M_{i,:}||_2=1 \ \forall i\in\mathbb{N}_1^n\}$</td>
    <td>Manifold of $n$-by-$n$ psd matrices of rank $k$ with unit diagonal elements.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Elliptope
manifold = Elliptope(n,k)
</code></pre>
    </td>
</tr>

<tr>
    <td>PSDFixedRank manifold<br />
    $\operatorname{PSD}_k^n \triangleq \{M\in\mathbb{R}^{n\times n}: M \succeq \mathbf{0}, \operatorname{rank}(M)=k\}$</td>
    <td>Manifold of $n$-by-$n$ symmetric/hermitian positive semidefinite matrices of rank $k$.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
# real
from pymanopt.manifolds import PSDFixedRank
manifold = PSDFixedRank(n,k)

# complex
from pymanopt.manifolds import PSDFixedRankComplex
manifold = PSDFixedRankComplex(n,k)
</code></pre>
    </td>
</tr>

<tr>
    <td>Sphere manifold<br />
    $\mathcal{S}^{m\times n} \triangleq \{M\in\mathbb{R}^{m\times n}:||M||_F=1\}$</td>
    <td>$m\times n$ matrices of unit Frobenius norm, i.e., the unit
    Sphere for $n=1$ (the default value of this optional argument).</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Sphere
manifold = Sphere(m)
</code></pre>
    </td>
</tr>

<tr>
    <td>Stiefel manifold<br />
    $V_{m,n} \triangleq \{P\in\mathbb{R}^{m\times n}: P^\top P=\mathbf{1}_{n\times n}\}$</td>
    <td>This is the manifold of projection matrices. For optional
    argument $k>1$ this instantiates the product manifold
    $\mathcal{St}^{m\times n}\times\cdots\times\mathcal{St}^{m\times n}$
    of $k$ Stiefel manifolds.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Stiefel
manifold = Stiefel(m,n)
</code></pre>
    </td>
</tr>

<tr class="topborder">
    <td>Product manifold<br />
    $\mathcal{M_1}\times \cdots \times \mathcal{M_l}$ for manifolds $\mathcal{M_1},...,\mathcal{M_l}$</td>
    <td>Product manifold of any of the manifolds listed above, e.g. $V_{m\times n}\times\mathbb{R}^{k\times l}$.</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.manifolds import Product, Stiefel, Euclidean
manifold = Product([Stiefel(m,n), Euclidean(k,l)])
</code></pre>
    </td>
</tr>

</table>


<h2>(3) Solvers</h2>

<h3>List of Solvers</h3>

<table id="solvers">

<tr>
    <th>solver</th>
    <th>description</th>
    <th>required codelines</th>
</tr>

<tr>
    <td>TrustRegions</td>
    <td>Second-order method that approximates the objective function by
    a quadratic surface and then updates the current estimate based on
    that</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.solvers import TrustRegions
solver = TrustRegions()
Xopt = solver.solve(problem)
</code></pre>
    </td>
</tr>

<tr>
    <td>SteepestDescent</td>
    <td>Classical first-order steepest descent algorithm</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.solvers import SteepestDescent
solver = SteepestDescent()
Xopt = solver.solve(problem)
</code></pre>
    </td>
</tr>

<tr>
    <td>ConjugateGradient</td>
    <td>Classical first-order conjugate gradient descent algorithm</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.solvers import ConjugateGradient
solver = ConjugateGradient()
Xopt = solver.solve(problem)
</code></pre>
    </td>
</tr>

<tr>
    <td>NelderMead</td>
    <td>Derivative-free optimisation</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.solvers import NelderMead
solver = NelderMead()
Xopt = solver.solve(problem)
</code></pre>
    </td>
</tr>

<tr>
    <td>ParticleSwarm</td>
    <td>Derivative-free optimisation</td>
    <td>
<pre class="prettyprint"><code class="language-py">
from pymanopt.solvers import ParticleSwarm
solver = ParticleSwarm()
Xopt = solver.solve(problem)
</code></pre>
    </td>
</tr>

</table>

</body>

</html>
