<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pymanopt.solvers.trust_regions &mdash; Pymanopt latest documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="canonical" href="pymanopt.org/_modules/pymanopt/solvers/trust_regions.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Pymanopt
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api-reference.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Pymanopt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>pymanopt.solvers.trust_regions</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pymanopt.solvers.trust_regions</h1><div class="highlight"><pre>
<span></span><span class="c1"># References, taken from trustregions.m in manopt:</span>

<span class="c1"># Please cite the Manopt paper as well as the research paper:</span>
<span class="c1">#     @Article{genrtr,</span>
<span class="c1">#       Title    = {Trust-region methods on {Riemannian} manifolds},</span>
<span class="c1">#       Author   = {Absil, P.-A. and Baker, C. G. and Gallivan, K. A.},</span>
<span class="c1">#       Journal  = {Foundations of Computational Mathematics},</span>
<span class="c1">#       Year     = {2007},</span>
<span class="c1">#       Number   = {3},</span>
<span class="c1">#       Pages    = {303--330},</span>
<span class="c1">#       Volume   = {7},</span>
<span class="c1">#       Doi      = {10.1007/s10208-005-0179-9}</span>
<span class="c1">#     }</span>
<span class="c1">#</span>
<span class="c1"># See also: steepestdescent conjugategradient manopt/examples</span>

<span class="c1"># An explicit, general listing of this algorithm, with preconditioning,</span>
<span class="c1"># can be found in the following paper:</span>
<span class="c1">#     @Article{boumal2015lowrank,</span>
<span class="c1">#       Title   = {Low-rank matrix completion via preconditioned optimization</span>
<span class="c1">#                   on the {G}rassmann manifold},</span>
<span class="c1">#       Author  = {Boumal, N. and Absil, P.-A.},</span>
<span class="c1">#       Journal = {Linear Algebra and its Applications},</span>
<span class="c1">#       Year    = {2015},</span>
<span class="c1">#       Pages   = {200--239},</span>
<span class="c1">#       Volume  = {475},</span>
<span class="c1">#       Doi     = {10.1016/j.laa.2015.02.027},</span>
<span class="c1">#     }</span>

<span class="c1"># When the Hessian is not specified, it is approximated with</span>
<span class="c1"># finite-differences of the gradient. The resulting method is called</span>
<span class="c1"># RTR-FD. Some convergence theory for it is available in this paper:</span>
<span class="c1"># @incollection{boumal2015rtrfd</span>
<span class="c1"># 	author={Boumal, N.},</span>
<span class="c1"># 	title={Riemannian trust regions with finite-difference Hessian</span>
<span class="c1">#                      approximations are globally convergent},</span>
<span class="c1"># 	year={2015},</span>
<span class="c1"># 	booktitle={Geometric Science of Information}</span>
<span class="c1"># }</span>


<span class="c1"># This file is part of Manopt: www.manopt.org.</span>
<span class="c1"># This code is an adaptation to Manopt of the original GenRTR code:</span>
<span class="c1"># RTR - Riemannian Trust-Region</span>
<span class="c1"># (c) 2004-2007, P.-A. Absil, C. G. Baker, K. A. Gallivan</span>
<span class="c1"># Florida State University</span>
<span class="c1"># School of Computational Science</span>
<span class="c1"># (http://www.math.fsu.edu/~cbaker/GenRTR/?page=download)</span>
<span class="c1"># See accompanying license file.</span>
<span class="c1"># The adaptation was executed by Nicolas Boumal.</span>

<span class="c1"># Ported to pymanopt by Jamie Townsend. January 2016.</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">pymanopt.solvers.solver</span> <span class="kn">import</span> <span class="n">Solver</span>


<div class="viewcode-block" id="TrustRegions"><a class="viewcode-back" href="../../../api-reference.html#pymanopt.solvers.trust_regions.TrustRegions">[docs]</a><span class="k">class</span> <span class="nc">TrustRegions</span><span class="p">(</span><span class="n">Solver</span><span class="p">):</span>
    <span class="p">(</span><span class="n">NEGATIVE_CURVATURE</span><span class="p">,</span> <span class="n">EXCEEDED_TR</span><span class="p">,</span> <span class="n">REACHED_TARGET_LINEAR</span><span class="p">,</span>
     <span class="n">REACHED_TARGET_SUPERLINEAR</span><span class="p">,</span> <span class="n">MAX_INNER_ITER</span><span class="p">,</span> <span class="n">MODEL_INCREASED</span><span class="p">)</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">TCG_STOP_REASONS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">NEGATIVE_CURVATURE</span><span class="p">:</span> <span class="s2">&quot;negative curvature&quot;</span><span class="p">,</span>
        <span class="n">EXCEEDED_TR</span><span class="p">:</span> <span class="s2">&quot;exceeded trust region&quot;</span><span class="p">,</span>
        <span class="n">REACHED_TARGET_LINEAR</span><span class="p">:</span> <span class="s2">&quot;reached target residual-kappa (linear)&quot;</span><span class="p">,</span>
        <span class="n">REACHED_TARGET_SUPERLINEAR</span><span class="p">:</span> <span class="s2">&quot;reached target residual-theta &quot;</span>
                                    <span class="s2">&quot;(superlinear)&quot;</span><span class="p">,</span>
        <span class="n">MAX_INNER_ITER</span><span class="p">:</span> <span class="s2">&quot;maximum inner iterations&quot;</span><span class="p">,</span>
        <span class="n">MODEL_INCREASED</span><span class="p">:</span> <span class="s2">&quot;model increased&quot;</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">miniter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">rho_prime</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">use_rand</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rho_regularization</span><span class="o">=</span><span class="mf">1e3</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trust regions algorithm based on trustregions.m from the</span>
<span class="sd">        Manopt MATLAB package.</span>

<span class="sd">        Also included is the Truncated (Steihaug-Toint) Conjugate-Gradient</span>
<span class="sd">        algorithm, based on tCG.m from the Manopt MATLAB package.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">miniter</span> <span class="o">=</span> <span class="n">miniter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span> <span class="o">=</span> <span class="n">kappa</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_prime</span> <span class="o">=</span> <span class="n">rho_prime</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span> <span class="o">=</span> <span class="n">use_rand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_regularization</span> <span class="o">=</span> <span class="n">rho_regularization</span>

<div class="viewcode-block" id="TrustRegions.solve"><a class="viewcode-back" href="../../../api-reference.html#pymanopt.solvers.trust_regions.TrustRegions.solve">[docs]</a>    <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mininner</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxinner</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">Delta_bar</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Delta0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">man</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">manifold</span>
        <span class="n">verbosity</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">verbosity</span>

        <span class="k">if</span> <span class="n">maxinner</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">maxinner</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">dim</span>

        <span class="c1"># Set default Delta_bar and Delta0 separately to deal with additional</span>
        <span class="c1"># logic: if Delta_bar is provided but not Delta0, let Delta0</span>
        <span class="c1"># automatically be some fraction of the provided Delta_bar.</span>
        <span class="k">if</span> <span class="n">Delta_bar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">Delta_bar</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">typicaldist</span>
            <span class="k">except</span> <span class="ne">NotImplementedError</span><span class="p">:</span>
                <span class="n">Delta_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">man</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Delta0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Delta0</span> <span class="o">=</span> <span class="n">Delta_bar</span> <span class="o">/</span> <span class="mi">8</span>

        <span class="n">cost</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">cost</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">grad</span>
        <span class="n">hess</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">hess</span>

        <span class="c1"># If no starting point is specified, generate one at random.</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>

        <span class="c1"># Initializations</span>
        <span class="n">time0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># k counts the outer (TR) iterations. The semantic is that k counts the</span>
        <span class="c1"># number of iterations fully executed so far.</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Initialize solution and companion measures: f(x), fgrad(x)</span>
        <span class="n">fx</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">fgradx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">norm_grad</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">)</span>

        <span class="c1"># Initialize the trust region radius</span>
        <span class="n">Delta</span> <span class="o">=</span> <span class="n">Delta0</span>

        <span class="c1"># To keep track of consecutive radius changes, so that we can warn the</span>
        <span class="c1"># user if it appears necessary.</span>
        <span class="n">consecutive_TRplus</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">consecutive_TRminus</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># ** Display:</span>
        <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimizing...&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:44s}</span><span class="s2">f: </span><span class="si">{:+.6e}</span><span class="s2">   |grad|: </span><span class="si">{:.6e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">fx</span><span class="p">),</span> <span class="n">norm_grad</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_start_optlog</span><span class="p">()</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># *************************</span>
            <span class="c1"># ** Begin TR Subproblem **</span>
            <span class="c1"># *************************</span>

            <span class="c1"># Determine eta0</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
                <span class="c1"># Pick the zero vector</span>
                <span class="n">eta</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">zerovec</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Random vector in T_x M (this has to be very small)</span>
                <span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="n">man</span><span class="o">.</span><span class="n">randvec</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="c1"># Must be inside trust region</span>
                <span class="k">while</span> <span class="n">man</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">Delta</span><span class="p">:</span>
                    <span class="n">eta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>

            <span class="c1"># Solve TR subproblem approximately</span>
            <span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">,</span> <span class="n">numit</span><span class="p">,</span> <span class="n">stop_inner</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_conjugate_gradient</span><span class="p">(</span>
                <span class="n">problem</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">Delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span><span class="p">,</span>
                <span class="n">mininner</span><span class="p">,</span> <span class="n">maxinner</span><span class="p">)</span>

            <span class="n">srstr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TCG_STOP_REASONS</span><span class="p">[</span><span class="n">stop_inner</span><span class="p">]</span>

            <span class="c1"># If using randomized approach, compare result with the Cauchy</span>
            <span class="c1"># point. Convergence proofs assume that we achieve at least (a</span>
            <span class="c1"># fraction of) the reduction of the Cauchy point. After this</span>
            <span class="c1"># if-block, either all eta-related quantities have been changed</span>
            <span class="c1"># consistently, or none of them have.</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
                <span class="n">used_cauchy</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="c1"># Check the curvature</span>
                <span class="n">Hg</span> <span class="o">=</span> <span class="n">hess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">)</span>
                <span class="n">g_Hg</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">Hg</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">g_Hg</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">tau_c</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tau_c</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">norm_grad</span> <span class="o">**</span> <span class="mi">3</span> <span class="o">/</span> <span class="p">(</span><span class="n">Delta</span> <span class="o">*</span> <span class="n">g_Hg</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># and generate the Cauchy point.</span>
                <span class="n">eta_c</span> <span class="o">=</span> <span class="o">-</span><span class="n">tau_c</span> <span class="o">*</span> <span class="n">Delta</span> <span class="o">/</span> <span class="n">norm_grad</span> <span class="o">*</span> <span class="n">fgradx</span>
                <span class="n">Heta_c</span> <span class="o">=</span> <span class="o">-</span><span class="n">tau_c</span> <span class="o">*</span> <span class="n">Delta</span> <span class="o">/</span> <span class="n">norm_grad</span> <span class="o">*</span> <span class="n">Hg</span>

                <span class="c1"># Now that we have computed the Cauchy point in addition to the</span>
                <span class="c1"># returned eta, we might as well keep the best of them.</span>
                <span class="n">mdle</span> <span class="o">=</span> <span class="p">(</span><span class="n">fx</span> <span class="o">+</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span> <span class="o">+</span>
                        <span class="mf">0.5</span> <span class="o">*</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Heta</span><span class="p">,</span> <span class="n">eta</span><span class="p">))</span>
                <span class="n">mdlec</span> <span class="o">=</span> <span class="p">(</span><span class="n">fx</span> <span class="o">+</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">eta_c</span><span class="p">)</span> <span class="o">+</span>
                         <span class="mf">0.5</span> <span class="o">*</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Heta_c</span><span class="p">,</span> <span class="n">eta_c</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">mdlec</span> <span class="o">&lt;</span> <span class="n">mdle</span><span class="p">:</span>
                    <span class="n">eta</span> <span class="o">=</span> <span class="n">eta_c</span>
                    <span class="n">Heta</span> <span class="o">=</span> <span class="n">Heta_c</span>
                    <span class="n">used_cauchy</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># This is only computed for logging purposes, because it may be</span>
            <span class="c1"># useful for some user-defined stopping criteria. If this is not</span>
            <span class="c1"># cheap for specific applications (compared to evaluating the</span>
            <span class="c1"># cost), we should reconsider this.</span>
            <span class="c1"># norm_eta = man.norm(x, eta)</span>

            <span class="c1"># Compute the tentative next iterate (the proposal)</span>
            <span class="n">x_prop</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">retr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>

            <span class="c1"># Compute the function value of the proposal</span>
            <span class="n">fx_prop</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">x_prop</span><span class="p">)</span>

            <span class="c1"># Will we accept the proposal or not? Check the performance of the</span>
            <span class="c1"># quadratic model against the actual cost.</span>
            <span class="n">rhonum</span> <span class="o">=</span> <span class="n">fx</span> <span class="o">-</span> <span class="n">fx_prop</span>
            <span class="n">rhoden</span> <span class="o">=</span> <span class="o">-</span><span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">)</span>

            <span class="c1"># rhonum could be anything.</span>
            <span class="c1"># rhoden should be nonnegative, as guaranteed by tCG, baring</span>
            <span class="c1"># numerical errors.</span>

            <span class="c1"># Heuristic -- added Dec. 2, 2013 (NB) to replace the former</span>
            <span class="c1"># heuristic. This heuristic is documented in the book by Conn Gould</span>
            <span class="c1"># and Toint on trust-region methods, section 17.4.2. rhonum</span>
            <span class="c1"># measures the difference between two numbers. Close to</span>
            <span class="c1"># convergence, these two numbers are very close to each other, so</span>
            <span class="c1"># that computing their difference is numerically challenging: there</span>
            <span class="c1"># may be a significant loss in accuracy. Since the acceptance or</span>
            <span class="c1"># rejection of the step is conditioned on the ratio between rhonum</span>
            <span class="c1"># and rhoden, large errors in rhonum result in a very large error</span>
            <span class="c1"># in rho, hence in erratic acceptance / rejection. Meanwhile, close</span>
            <span class="c1"># to convergence, steps are usually trustworthy and we should</span>
            <span class="c1"># transition to a Newton- like method, with rho=1 consistently. The</span>
            <span class="c1"># heuristic thus shifts both rhonum and rhoden by a small amount</span>
            <span class="c1"># such that far from convergence, the shift is irrelevant and close</span>
            <span class="c1"># to convergence, the ratio rho goes to 1, effectively promoting</span>
            <span class="c1"># acceptance of the step.  The rationale is that close to</span>
            <span class="c1"># convergence, both rhonum and rhoden are quadratic in the distance</span>
            <span class="c1"># between x and x_prop. Thus, when this distance is on the order of</span>
            <span class="c1"># sqrt(eps), the value of rhonum and rhoden is on the order of eps,</span>
            <span class="c1"># which is indistinguishable from the numerical error, resulting in</span>
            <span class="c1"># badly estimated rho&#39;s.</span>
            <span class="c1"># For abs(fx) &lt; 1, this heuristic is invariant under offsets of f</span>
            <span class="c1"># but not under scaling of f. For abs(fx) &gt; 1, the opposite holds.</span>
            <span class="c1"># This should not alarm us, as this heuristic only triggers at the</span>
            <span class="c1"># very last iterations if very fine convergence is demanded.</span>
            <span class="n">rho_reg</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fx</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_regularization</span>
            <span class="n">rhonum</span> <span class="o">=</span> <span class="n">rhonum</span> <span class="o">+</span> <span class="n">rho_reg</span>
            <span class="n">rhoden</span> <span class="o">=</span> <span class="n">rhoden</span> <span class="o">+</span> <span class="n">rho_reg</span>

            <span class="c1"># This is always true if a linear, symmetric operator is used for</span>
            <span class="c1"># the Hessian (approximation) and if we had infinite numerical</span>
            <span class="c1"># precision.  In practice, nonlinear approximations of the Hessian</span>
            <span class="c1"># such as the built-in finite difference approximation and finite</span>
            <span class="c1"># numerical accuracy can cause the model to increase. In such</span>
            <span class="c1"># scenarios, we decide to force a rejection of the step and a</span>
            <span class="c1"># reduction of the trust-region radius. We test the sign of the</span>
            <span class="c1"># regularized rhoden since the regularization is supposed to</span>
            <span class="c1"># capture the accuracy to which rhoden is computed: if rhoden were</span>
            <span class="c1"># negative before regularization but not after, that should not be</span>
            <span class="c1"># (and is not) detected as a failure.</span>
            <span class="c1">#</span>
            <span class="c1"># Note (Feb. 17, 2015, NB): the most recent version of tCG already</span>
            <span class="c1"># includes a mechanism to ensure model decrease if the Cauchy step</span>
            <span class="c1"># attained a decrease (which is theoretically the case under very</span>
            <span class="c1"># lax assumptions). This being said, it is always possible that</span>
            <span class="c1"># numerical errors will prevent this, so that it is good to keep a</span>
            <span class="c1"># safeguard.</span>
            <span class="c1">#</span>
            <span class="c1"># The current strategy is that, if this should happen, then we</span>
            <span class="c1"># reject the step and reduce the trust region radius. This also</span>
            <span class="c1"># ensures that the actual cost values are monotonically decreasing.</span>
            <span class="n">model_decreased</span> <span class="o">=</span> <span class="p">(</span><span class="n">rhoden</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">model_decreased</span><span class="p">:</span>
                <span class="n">srstr</span> <span class="o">=</span> <span class="n">srstr</span> <span class="o">+</span> <span class="s2">&quot;, model did not decrease&quot;</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="n">rhonum</span> <span class="o">/</span> <span class="n">rhoden</span>
            <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
                <span class="c1"># Added June 30, 2015 following observation by BM.  With this</span>
                <span class="c1"># modification, it is guaranteed that a step rejection is</span>
                <span class="c1"># always accompanied by a TR reduction. This prevents</span>
                <span class="c1"># stagnation in this &quot;corner case&quot; (NaN&#39;s really aren&#39;t</span>
                <span class="c1"># supposed to occur, but it&#39;s nice if we can handle them</span>
                <span class="c1"># nonetheless).</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;rho is NaN! Forcing a radius decrease. This should &quot;</span>
                      <span class="s2">&quot;not happen.&quot;</span><span class="p">)</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

            <span class="c1"># Choose the new TR radius based on the model performance</span>
            <span class="n">trstr</span> <span class="o">=</span> <span class="s2">&quot;   &quot;</span>
            <span class="c1"># If the actual decrease is smaller than 1/4 of the predicted</span>
            <span class="c1"># decrease, then reduce the TR radius.</span>
            <span class="k">if</span> <span class="n">rho</span> <span class="o">&lt;</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mi">4</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">model_decreased</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">rho</span><span class="p">):</span>
                <span class="n">trstr</span> <span class="o">=</span> <span class="s2">&quot;TR-&quot;</span>
                <span class="n">Delta</span> <span class="o">=</span> <span class="n">Delta</span> <span class="o">/</span> <span class="mi">4</span>
                <span class="n">consecutive_TRplus</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">consecutive_TRminus</span> <span class="o">=</span> <span class="n">consecutive_TRminus</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">consecutive_TRminus</span> <span class="o">&gt;=</span> <span class="mi">5</span> <span class="ow">and</span> <span class="n">verbosity</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">consecutive_TRminus</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Detected many consecutive TR- (radius &quot;</span>
                          <span class="s2">&quot;decreases).&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Consider decreasing options.Delta_bar &quot;</span>
                          <span class="s2">&quot;by an order of magnitude.&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Current values: Delta_bar = </span><span class="si">{:g}</span><span class="s2"> and &quot;</span>
                          <span class="s2">&quot;Delta0 = </span><span class="si">{:g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Delta_bar</span><span class="p">,</span> <span class="n">Delta0</span><span class="p">))</span>
            <span class="c1"># If the actual decrease is at least 3/4 of the precicted decrease</span>
            <span class="c1"># and the tCG (inner solve) hit the TR boundary, increase the TR</span>
            <span class="c1"># radius. We also keep track of the number of consecutive</span>
            <span class="c1"># trust-region radius increases. If there are many, this may</span>
            <span class="c1"># indicate the need to adapt the initial and maximum radii.</span>
            <span class="k">elif</span> <span class="n">rho</span> <span class="o">&gt;</span> <span class="mf">3.0</span> <span class="o">/</span> <span class="mi">4</span> <span class="ow">and</span> <span class="p">(</span><span class="n">stop_inner</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">NEGATIVE_CURVATURE</span> <span class="ow">or</span>
                                    <span class="n">stop_inner</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">EXCEEDED_TR</span><span class="p">):</span>
                <span class="n">trstr</span> <span class="o">=</span> <span class="s2">&quot;TR+&quot;</span>
                <span class="n">Delta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Delta</span><span class="p">,</span> <span class="n">Delta_bar</span><span class="p">)</span>
                <span class="n">consecutive_TRminus</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">consecutive_TRplus</span> <span class="o">=</span> <span class="n">consecutive_TRplus</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">consecutive_TRplus</span> <span class="o">&gt;=</span> <span class="mi">5</span> <span class="ow">and</span> <span class="n">verbosity</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">consecutive_TRplus</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Detected many consecutive TR+ (radius &quot;</span>
                          <span class="s2">&quot;increases).&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Consider increasing options.Delta_bar &quot;</span>
                          <span class="s2">&quot;by an order of magnitude.&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; +++ Current values: Delta_bar = </span><span class="si">{:g}</span><span class="s2"> and &quot;</span>
                          <span class="s2">&quot;Delta0 = </span><span class="si">{:g}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Delta_bar</span><span class="p">,</span> <span class="n">Delta0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Otherwise, keep the TR radius constant.</span>
                <span class="n">consecutive_TRplus</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">consecutive_TRminus</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Choose to accept or reject the proposed step based on the model</span>
            <span class="c1"># performance. Note the strict inequality.</span>
            <span class="k">if</span> <span class="n">model_decreased</span> <span class="ow">and</span> <span class="n">rho</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_prime</span><span class="p">:</span>
                <span class="c1"># accept = True</span>
                <span class="n">accstr</span> <span class="o">=</span> <span class="s2">&quot;acc&quot;</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x_prop</span>
                <span class="n">fx</span> <span class="o">=</span> <span class="n">fx_prop</span>
                <span class="n">fgradx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">norm_grad</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># accept = False</span>
                <span class="n">accstr</span> <span class="o">=</span> <span class="s2">&quot;REJ&quot;</span>

            <span class="c1"># k is the number of iterations we have accomplished.</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="c1"># ** Display:</span>
            <span class="k">if</span> <span class="n">verbosity</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3s}</span><span class="s2"> </span><span class="si">{:.3s}</span><span class="s2">   k: </span><span class="si">{:5d}</span><span class="s2">     num_inner: &quot;</span>
                      <span class="s2">&quot;</span><span class="si">{:5d}</span><span class="s2">     f: </span><span class="si">{:+e}</span><span class="s2">   |grad|: </span><span class="si">{:e}</span><span class="s2">   &quot;</span>
                      <span class="s2">&quot;</span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accstr</span><span class="p">,</span> <span class="n">trstr</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">numit</span><span class="p">,</span>
                                    <span class="nb">float</span><span class="p">(</span><span class="n">fx</span><span class="p">),</span> <span class="n">norm_grad</span><span class="p">,</span> <span class="n">srstr</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span> <span class="ow">and</span> <span class="n">used_cauchy</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;USED CAUCHY POINT&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3s}</span><span class="s2"> </span><span class="si">{:.3s}</span><span class="s2">    k: </span><span class="si">{:5d}</span><span class="s2">     num_inner: &quot;</span>
                      <span class="s2">&quot;</span><span class="si">{:5d}</span><span class="s2">     </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accstr</span><span class="p">,</span> <span class="n">trstr</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">numit</span><span class="p">,</span> <span class="n">srstr</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;       f(x) : </span><span class="si">{:+e}</span><span class="s2">     |grad| : &quot;</span>
                      <span class="s2">&quot;</span><span class="si">{:e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">norm_grad</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;        rho : </span><span class="si">{:e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rho</span><span class="p">))</span>

            <span class="c1"># ** CHECK STOPPING criteria</span>
            <span class="n">stop_reason</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_stopping_criterion</span><span class="p">(</span>
                <span class="n">time0</span><span class="p">,</span> <span class="n">gradnorm</span><span class="o">=</span><span class="n">norm_grad</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">stop_reason</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">stop_reason</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logverbosity</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_optlog</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fx</span><span class="p">,</span> <span class="n">stop_reason</span><span class="p">,</span> <span class="n">time0</span><span class="p">,</span>
                              <span class="n">gradnorm</span><span class="o">=</span><span class="n">norm_grad</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optlog</span></div>

    <span class="k">def</span> <span class="nf">_truncated_conjugate_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">Delta</span><span class="p">,</span>
                                      <span class="n">theta</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">mininner</span><span class="p">,</span> <span class="n">maxinner</span><span class="p">):</span>
        <span class="n">man</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">manifold</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">inner</span>
        <span class="n">hess</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">hess</span>
        <span class="n">precon</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">precon</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>  <span class="c1"># and therefore, eta == 0</span>
            <span class="n">Heta</span> <span class="o">=</span> <span class="n">man</span><span class="o">.</span><span class="n">zerovec</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">fgradx</span>
            <span class="n">e_Pe</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># and therefore, no preconditioner</span>
            <span class="c1"># eta (presumably) ~= 0 was provided by the caller.</span>
            <span class="n">Heta</span> <span class="o">=</span> <span class="n">hess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">fgradx</span> <span class="o">+</span> <span class="n">Heta</span>
            <span class="n">e_Pe</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>

        <span class="n">r_r</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">norm_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">r_r</span><span class="p">)</span>
        <span class="n">norm_r0</span> <span class="o">=</span> <span class="n">norm_r</span>

        <span class="c1"># Precondition the residual</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">precon</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">r</span>

        <span class="c1"># Compute z&#39;*r</span>
        <span class="n">z_r</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">d_Pd</span> <span class="o">=</span> <span class="n">z_r</span>

        <span class="c1"># Initial search direction</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">z</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
            <span class="n">e_Pd</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">e_Pd</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>

        <span class="c1"># If the Hessian or a linear Hessian approximation is in use, it is</span>
        <span class="c1"># theoretically guaranteed that the model value decreases strictly with</span>
        <span class="c1"># each iteration of tCG. Hence, there is no need to monitor the model</span>
        <span class="c1"># value. But, when a nonlinear Hessian approximation is used (such as</span>
        <span class="c1"># the built-in finite-difference approximation for example), the model</span>
        <span class="c1"># may increase. It is then important to terminate the tCG iterations</span>
        <span class="c1"># and return the previous (the best-so-far) iterate. The variable below</span>
        <span class="c1"># will hold the model value.</span>

        <span class="k">def</span> <span class="nf">model_fun</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">fgradx</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
            <span class="n">model_value</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_value</span> <span class="o">=</span> <span class="n">model_fun</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">)</span>

        <span class="c1"># Pre-assume termination because j == end.</span>
        <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_INNER_ITER</span>

        <span class="c1"># Begin inner/tCG loop.</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">maxinner</span><span class="p">)):</span>
            <span class="c1"># This call is the computationally intensive step</span>
            <span class="n">Hdelta</span> <span class="o">=</span> <span class="n">hess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>

            <span class="c1"># Compute curvature (often called kappa)</span>
            <span class="n">d_Hd</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">Hdelta</span><span class="p">)</span>

            <span class="c1"># Note that if d_Hd == 0, we will exit at the next &quot;if&quot; anyway.</span>
            <span class="k">if</span> <span class="n">d_Hd</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">alpha</span> <span class="o">=</span> <span class="n">z_r</span> <span class="o">/</span> <span class="n">d_Hd</span>
                <span class="c1"># &lt;neweta,neweta&gt;_P =</span>
                <span class="c1"># &lt;eta,eta&gt;_P</span>
                <span class="c1"># + 2*alpha*&lt;eta,delta&gt;_P</span>
                <span class="c1"># + alpha*alpha*&lt;delta,delta&gt;_P</span>
                <span class="n">e_Pe_new</span> <span class="o">=</span> <span class="n">e_Pe</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">e_Pd</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">d_Pd</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">e_Pe_new</span> <span class="o">=</span> <span class="n">e_Pe</span>

            <span class="c1"># Check against negative curvature and trust-region radius</span>
            <span class="c1"># violation. If either condition triggers, we bail out.</span>
            <span class="k">if</span> <span class="n">d_Hd</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">e_Pe_new</span> <span class="o">&gt;=</span> <span class="n">Delta</span><span class="o">**</span><span class="mi">2</span><span class="p">:</span>
                <span class="c1"># want</span>
                <span class="c1">#  ee = &lt;eta,eta&gt;_prec,x</span>
                <span class="c1">#  ed = &lt;eta,delta&gt;_prec,x</span>
                <span class="c1">#  dd = &lt;delta,delta&gt;_prec,x</span>
                <span class="n">tau</span> <span class="o">=</span> <span class="p">((</span><span class="o">-</span><span class="n">e_Pd</span> <span class="o">+</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">e_Pd</span> <span class="o">*</span> <span class="n">e_Pd</span> <span class="o">+</span>
                                <span class="n">d_Pd</span> <span class="o">*</span> <span class="p">(</span><span class="n">Delta</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">e_Pe</span><span class="p">)))</span> <span class="o">/</span> <span class="n">d_Pd</span><span class="p">)</span>

                <span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">delta</span>

                <span class="c1"># If only a nonlinear Hessian approximation is available, this</span>
                <span class="c1"># is only approximately correct, but saves an additional</span>
                <span class="c1"># Hessian call.</span>
                <span class="n">Heta</span> <span class="o">=</span> <span class="n">Heta</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">Hdelta</span>

                <span class="c1"># Technically, we may want to verify that this new eta is</span>
                <span class="c1"># indeed better than the previous eta before returning it (this</span>
                <span class="c1"># is always the case if the Hessian approximation is linear,</span>
                <span class="c1"># but I am unsure whether it is the case or not for nonlinear</span>
                <span class="c1"># approximations.) At any rate, the impact should be limited,</span>
                <span class="c1"># so in the interest of code conciseness (if we can still hope</span>
                <span class="c1"># for that), we omit this.</span>

                <span class="k">if</span> <span class="n">d_Hd</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">NEGATIVE_CURVATURE</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">EXCEEDED_TR</span>
                <span class="k">break</span>

            <span class="c1"># No negative curvature and eta_prop inside TR: accept it.</span>
            <span class="n">e_Pe</span> <span class="o">=</span> <span class="n">e_Pe_new</span>
            <span class="n">new_eta</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>

            <span class="c1"># If only a nonlinear Hessian approximation is available, this is</span>
            <span class="c1"># only approximately correct, but saves an additional Hessian call.</span>
            <span class="n">new_Heta</span> <span class="o">=</span> <span class="n">Heta</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">Hdelta</span>

            <span class="c1"># Verify that the model cost decreased in going from eta to</span>
            <span class="c1"># new_eta. If it did not (which can only occur if the Hessian</span>
            <span class="c1"># approximation is nonlinear or because of numerical errors), then</span>
            <span class="c1"># we return the previous eta (which necessarily is the best reached</span>
            <span class="c1"># so far, according to the model cost). Otherwise, we accept the</span>
            <span class="c1"># new eta and go on.</span>
            <span class="n">new_model_value</span> <span class="o">=</span> <span class="n">model_fun</span><span class="p">(</span><span class="n">new_eta</span><span class="p">,</span> <span class="n">new_Heta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_model_value</span> <span class="o">&gt;=</span> <span class="n">model_value</span><span class="p">:</span>
                <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">MODEL_INCREASED</span>
                <span class="k">break</span>

            <span class="n">eta</span> <span class="o">=</span> <span class="n">new_eta</span>
            <span class="n">Heta</span> <span class="o">=</span> <span class="n">new_Heta</span>
            <span class="n">model_value</span> <span class="o">=</span> <span class="n">new_model_value</span>

            <span class="c1"># Update the residual.</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">Hdelta</span>

            <span class="c1"># Compute new norm of r.</span>
            <span class="n">r_r</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
            <span class="n">norm_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">r_r</span><span class="p">)</span>

            <span class="c1"># Check kappa/theta stopping criterion.</span>
            <span class="c1"># Note that it is somewhat arbitrary whether to check this stopping</span>
            <span class="c1"># criterion on the r&#39;s (the gradients) or on the z&#39;s (the</span>
            <span class="c1"># preconditioned gradients). [CGT2000], page 206, mentions both as</span>
            <span class="c1"># acceptable criteria.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;=</span> <span class="n">mininner</span> <span class="ow">and</span>
               <span class="n">norm_r</span> <span class="o">&lt;=</span> <span class="n">norm_r0</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">norm_r0</span><span class="o">**</span><span class="n">theta</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)):</span>
                <span class="c1"># Residual is small enough to quit</span>
                <span class="k">if</span> <span class="n">kappa</span> <span class="o">&lt;</span> <span class="n">norm_r0</span> <span class="o">**</span> <span class="n">theta</span><span class="p">:</span>
                    <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">REACHED_TARGET_LINEAR</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">stop_tCG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">REACHED_TARGET_SUPERLINEAR</span>
                <span class="k">break</span>

            <span class="c1"># Precondition the residual.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rand</span><span class="p">:</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">precon</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">r</span>

            <span class="c1"># Save the old z&#39;*r.</span>
            <span class="n">zold_rold</span> <span class="o">=</span> <span class="n">z_r</span>
            <span class="c1"># Compute new z&#39;*r.</span>
            <span class="n">z_r</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

            <span class="c1"># Compute new search direction</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">z_r</span> <span class="o">/</span> <span class="n">zold_rold</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">z</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">delta</span>

            <span class="c1"># Update new P-norms and P-dots [CGT2000, eq. 7.5.6 &amp; 7.5.7].</span>
            <span class="n">e_Pd</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">e_Pd</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">d_Pd</span><span class="p">)</span>
            <span class="n">d_Pd</span> <span class="o">=</span> <span class="n">z_r</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">d_Pd</span>

        <span class="k">return</span> <span class="n">eta</span><span class="p">,</span> <span class="n">Heta</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">stop_tCG</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2021, Jamie Townsend, Niklas Koep, Sebastian Weichwald.
      <span class="lastupdated">Last updated on Nov 10, 2021.
      </span></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>