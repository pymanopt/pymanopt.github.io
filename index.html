<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML+RDFa 1.1//EN" "http://www.w3.org/MarkUp/DTD/xhtml-rdfa-2.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" dir="ltr" id="index">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>pymanopt</title>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>

<body>

<p>This site is under construction. Please refer to this
<a href="https://github.com/pymanopt/pymanopt">github repository</a> in
the meanwhile.</p>


<h1>pymanopt</h1>

<p>pymanopt is a python toolbox for manifold optimization that computes
gradients and hessians automatically. It builds upon the MATLAB package
<a href="http://manopt.org/">Manopt</a> but is otherwise independent of
it. Pymanopt aims to lower the barriers for users wishing to use state
of the art manifold optimization techniques even further, by relying on
automatic differentiation for computing gradients and hessians, saving
users time and saving them from potential calculation and
implementiation errors.</p>

<p>pymanopt is modular and hence easy to use. Usually only the following
steps are required:</p>
<ol>
    <li>defininition of the function $f:\mathcal{M}\to \mathbb{R}$ to 
    minimise</li>
    <li>instantiation of the pymanopt manifold $\mathcal{M}$ to optimise
    over</li>
    <li>instantiation of a pymanopt solver</li>
</ol>
<p>If needed by the solver, pymanopt will compute the gradient and
hessian automatically.</p>


<h2>Manifolds</h2>


<h2>Solvers</h2>


</body>

</html>
